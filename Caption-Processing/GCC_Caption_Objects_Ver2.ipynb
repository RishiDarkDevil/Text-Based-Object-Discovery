{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tI2JPeWk9_e3"
   },
   "source": [
    "### Connect Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the [COLAB NOTEBOOK HERE](https://colab.research.google.com/drive/1W_E17Ei0KJVReYnmoiYwEtPzBu-nIeac?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYgIlFY09zxr",
    "outputId": "e09187f9-a5f5-4b98-c674-aa117ecbb9bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLofUFMwACJJ"
   },
   "source": [
    "Put your path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bwBL2EYN91bc"
   },
   "outputs": [],
   "source": [
    "!cd '/content/drive/MyDrive/AIISC-Internship/text-based-object-discovery'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yRXkRovRAcS2"
   },
   "outputs": [],
   "source": [
    "PATH = '/content/drive/MyDrive/AIISC-Internship/text-based-object-discovery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Mac or PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/Users/rishideychowdhury/Desktop/Text-Based-Object-Discovery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8rvljtL1abQ"
   },
   "source": [
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl1ekBkx09AQ"
   },
   "source": [
    "`Stanza`, Stanford NLP Package benefits from `GPU` so enable it under `View Resources > Change runtime type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wYJ_MPw_0URj",
    "outputId": "e2cb62f4-1f24-4dc7-9668-f33857c43937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDKLBzgl0e0W",
    "outputId": "b6e81da2-8564-4e43-883f-479a65df13bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting stanza\n",
      "  Downloading stanza-1.4.2-py3-none-any.whl (691 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m691.3/691.3 KB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.8/dist-packages (from stanza) (3.19.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from stanza) (1.15.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from stanza) (1.13.0+cu116)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stanza) (1.21.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from stanza) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from stanza) (2.25.1)\n",
      "Collecting emoji\n",
      "  Downloading emoji-2.2.0.tar.gz (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 KB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->stanza) (4.0.0)\n",
      "Building wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-2.2.0-py3-none-any.whl size=234926 sha256=d2a4665f05147323428d550628ec8f458cfc02d2e65ebb14f3da9bd58dea2965\n",
      "  Stored in directory: /root/.cache/pip/wheels/86/62/9e/a6b27a681abcde69970dbc0326ff51955f3beac72f15696984\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji, stanza\n",
      "Successfully installed emoji-2.2.0 stanza-1.4.2\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (2022.6.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.8/dist-packages (from ftfy) (0.2.5)\n",
      "Installing collected packages: ftfy\n",
      "Successfully installed ftfy-6.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza # for stanford pos tagger\n",
    "!pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uU9_nV4_0aQ8"
   },
   "source": [
    "### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ue3SU-yo0fKZ"
   },
   "source": [
    "We will load the necessary libraries required for extracting objects from prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "C0wV7IAz15g8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuY33h94WGxb"
   },
   "source": [
    "Download the stopwords for removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InA4AEJnWCiP",
    "outputId": "4a8239e9-b0e1-4fc2-b0a7-1458d8461c49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rishideychowdhury/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rishideychowdhury/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rishideychowdhury/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/rishideychowdhury/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/rishideychowdhury/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "df6b06ecb56f423682c0b81450369c68",
      "365f9fc1f1f44502b22abe715e797a10",
      "1fbdc06fb1544d53a05533382b9c0062",
      "67fcbabbc7e94682a8d032fe4ed5144d",
      "2da511597a914db7b4ddf749852b331d",
      "9710fd246f1943258ba37cc8d6454b62",
      "5ac46403bd4044318527c0adfed0f672",
      "13293d3dbf7d4fb580c772e0e0dfcc9e",
      "0540e337651b4a158d5dffabb494d745",
      "ecc24e7ae09b432599b2ee56a4a57e09",
      "72f1b6b4703740fca72516e15c0214fd",
      "6f0f42079f8d48f6a82daab7cc927076",
      "fb4da8ef7a04451487731260764d7468",
      "c1ea0ca2be8f4cd39a5168fdced8264a",
      "20127b2249424758aaac276817af28a5",
      "14391e8237d44f2ba6e1890828233088",
      "d4c72b61447b4b78b1e82a2ca93a365c",
      "6b61994192e74430957f414859c3c28f",
      "71845a3840d54187b7120b16c8406194",
      "d4251c4227fc4efa8d6400bbd4695171",
      "325f39c1cb444e9b85a2360323d204ce",
      "d3155ecf834340609b9dc25df5cec3a2"
     ]
    },
    "id": "Ks3LM5iMS1Nl",
    "outputId": "6d7c4401-56af-461a-84d6-5bf9f274d873"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a329c8c5fc8b4e9d980af4d3a9f13576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 19:20:25 INFO: Downloading default packages for language: en (English) ...\n",
      "2023-01-06 19:20:26 INFO: File exists: /Users/rishideychowdhury/stanza_resources/en/default.zip\n",
      "2023-01-06 19:20:29 INFO: Finished downloading models and saved to /Users/rishideychowdhury/stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxsZiD_M1VSS"
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na1LrNBN2Jgf"
   },
   "source": [
    "Below, we load the `Google Conceptual Caption` annotations to extract the captions to continue further with extracting the objects from each caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "89WD3a8FxLWF"
   },
   "outputs": [],
   "source": [
    "train_file = pd.read_csv(os.path.join(PATH, 'Data/Goggle-Conceptual-Caption/Train_GCC-training.tsv'), sep='\\t', names=['captions', 'url'])\n",
    "val_file = pd.read_csv(os.path.join(PATH, 'Data/Goggle-Conceptual-Caption/Validation_GCC-1.1.0-Validation.tsv'), sep='\\t', names=['captions', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "OO9vNlmggfBy",
    "outputId": "f274f7cb-bbf1-4047-bcb6-1fbda14254f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very typical bus station</td>\n",
       "      <td>http://lh6.ggpht.com/-IvRtNLNcG8o/TpFyrudaT6I/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sierra looked stunning in this top and this sk...</td>\n",
       "      <td>http://78.media.tumblr.com/3b133294bdc7c7784b7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>young confused girl standing in front of a war...</td>\n",
       "      <td>https://media.gettyimages.com/photos/young-con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>interior design of modern living room with fir...</td>\n",
       "      <td>https://thumb1.shutterstock.com/display_pic_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cybernetic scene isolated on white background .</td>\n",
       "      <td>https://thumb1.shutterstock.com/display_pic_wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318328</th>\n",
       "      <td>the teams line up for a photo after kick - off</td>\n",
       "      <td>https://i0.wp.com/i.dailymail.co.uk/i/pix/2015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318329</th>\n",
       "      <td>stickers given to delegates at the convention .</td>\n",
       "      <td>http://cdn.radioiowa.com/wp-content/uploads/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318330</th>\n",
       "      <td>this is my very favourite design that i recent...</td>\n",
       "      <td>https://i.pinimg.com/736x/96/f0/77/96f07728efe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318331</th>\n",
       "      <td>man driving a car through the mountains</td>\n",
       "      <td>https://www.quickenloans.com/blog/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318332</th>\n",
       "      <td>a longtail boat with a flag goes by spectacula...</td>\n",
       "      <td>http://l7.alamy.com/zooms/338c4740f7b2480dbb72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3318333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  captions  \\\n",
       "0                               a very typical bus station   \n",
       "1        sierra looked stunning in this top and this sk...   \n",
       "2        young confused girl standing in front of a war...   \n",
       "3        interior design of modern living room with fir...   \n",
       "4          cybernetic scene isolated on white background .   \n",
       "...                                                    ...   \n",
       "3318328     the teams line up for a photo after kick - off   \n",
       "3318329    stickers given to delegates at the convention .   \n",
       "3318330  this is my very favourite design that i recent...   \n",
       "3318331            man driving a car through the mountains   \n",
       "3318332  a longtail boat with a flag goes by spectacula...   \n",
       "\n",
       "                                                       url  \n",
       "0        http://lh6.ggpht.com/-IvRtNLNcG8o/TpFyrudaT6I/...  \n",
       "1        http://78.media.tumblr.com/3b133294bdc7c7784b7...  \n",
       "2        https://media.gettyimages.com/photos/young-con...  \n",
       "3        https://thumb1.shutterstock.com/display_pic_wi...  \n",
       "4        https://thumb1.shutterstock.com/display_pic_wi...  \n",
       "...                                                    ...  \n",
       "3318328  https://i0.wp.com/i.dailymail.co.uk/i/pix/2015...  \n",
       "3318329  http://cdn.radioiowa.com/wp-content/uploads/20...  \n",
       "3318330  https://i.pinimg.com/736x/96/f0/77/96f07728efe...  \n",
       "3318331  https://www.quickenloans.com/blog/wp-content/u...  \n",
       "3318332  http://l7.alamy.com/zooms/338c4740f7b2480dbb72...  \n",
       "\n",
       "[3318333 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "VqjuTFtPghia",
    "outputId": "1b87b58c-7467-464e-9a46-7e64d3e0a723"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>captions</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author : a life in photography -- in pictures</td>\n",
       "      <td>https://i.pinimg.com/736x/66/01/6c/66016c3ba27...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>an angler fishes river on a snowy day .</td>\n",
       "      <td>http://www.standard.net/image/2015/02/04/800x_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>photograph of the sign being repaired by brave...</td>\n",
       "      <td>http://indianapolis-photos.funcityfinder.com/f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the player staring intently at a computer scre...</td>\n",
       "      <td>http://www.abc.net.au/news/image/9066492-3x2-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>globes : the green 3d person carrying in hands...</td>\n",
       "      <td>https://www.featurepics.com/StockImage/2009031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15835</th>\n",
       "      <td>a bougainvillea with pink flowers on a white b...</td>\n",
       "      <td>https://media.istockphoto.com/photos/bougainvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15836</th>\n",
       "      <td>ingredient hanging over river during festival</td>\n",
       "      <td>http://l7.alamy.com/zooms/4e49c7b4c0274166bb07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15837</th>\n",
       "      <td>the general circulation of the atmosphere</td>\n",
       "      <td>http://slideplayer.com/5036014/16/images/22/Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15838</th>\n",
       "      <td>young teenager and her black horse in a traini...</td>\n",
       "      <td>https://www.featurepics.com/StockImage/2008082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15839</th>\n",
       "      <td>person warms up during a game against american...</td>\n",
       "      <td>https://media.gettyimages.com/photos/malik-ros...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15840 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                captions  \\\n",
       "0          author : a life in photography -- in pictures   \n",
       "1                an angler fishes river on a snowy day .   \n",
       "2      photograph of the sign being repaired by brave...   \n",
       "3      the player staring intently at a computer scre...   \n",
       "4      globes : the green 3d person carrying in hands...   \n",
       "...                                                  ...   \n",
       "15835  a bougainvillea with pink flowers on a white b...   \n",
       "15836      ingredient hanging over river during festival   \n",
       "15837          the general circulation of the atmosphere   \n",
       "15838  young teenager and her black horse in a traini...   \n",
       "15839  person warms up during a game against american...   \n",
       "\n",
       "                                                     url  \n",
       "0      https://i.pinimg.com/736x/66/01/6c/66016c3ba27...  \n",
       "1      http://www.standard.net/image/2015/02/04/800x_...  \n",
       "2      http://indianapolis-photos.funcityfinder.com/f...  \n",
       "3      http://www.abc.net.au/news/image/9066492-3x2-7...  \n",
       "4      https://www.featurepics.com/StockImage/2009031...  \n",
       "...                                                  ...  \n",
       "15835  https://media.istockphoto.com/photos/bougainvi...  \n",
       "15836  http://l7.alamy.com/zooms/4e49c7b4c0274166bb07...  \n",
       "15837  http://slideplayer.com/5036014/16/images/22/Th...  \n",
       "15838  https://www.featurepics.com/StockImage/2008082...  \n",
       "15839  https://media.gettyimages.com/photos/malik-ros...  \n",
       "\n",
       "[15840 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCEvhAFxzaO6"
   },
   "source": [
    "Now, we load the captions for the train and validation set captions in lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ddu67lC2y74U"
   },
   "outputs": [],
   "source": [
    "prompts_train = list(train_file['captions'])\n",
    "prompts_val = list(val_file['captions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVYyBvLPzGYV",
    "outputId": "2a1fb2bf-2e4c-42f3-df3d-29270190170c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***train captions***\n",
      " a very typical bus station\n",
      "sierra looked stunning in this top and this skirt while performing with person at their former university\n",
      "young confused girl standing in front of a wardrobe\n",
      "interior design of modern living room with fireplace in a new house\n",
      "cybernetic scene isolated on white background .\n",
      "\n",
      "Number of train captions: 3318333\n",
      "\n",
      "\n",
      "***validation captions:***\n",
      " author : a life in photography -- in pictures\n",
      "an angler fishes river on a snowy day .\n",
      "photograph of the sign being repaired by brave person\n",
      "the player staring intently at a computer screen .\n",
      "globes : the green 3d person carrying in hands globe\n",
      "\n",
      "Number of train captions: 15840\n"
     ]
    }
   ],
   "source": [
    "def show_captions():\n",
    "  print('***train captions***\\n', '\\n'.join(prompts_train[:5]))\n",
    "  print()\n",
    "  print('Number of train captions:', len(prompts_train))\n",
    "  print()\n",
    "  print()\n",
    "  print('***validation captions:***\\n', '\\n'.join(prompts_val[:5]))\n",
    "  print()\n",
    "  print('Number of train captions:', len(prompts_val))\n",
    "\n",
    "show_captions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BErRDos2AB6B"
   },
   "source": [
    "### Caption Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6F-PdFL3JQP"
   },
   "source": [
    "Cleaning the prompts. I adopt few ways to clean the prompt:\n",
    "- Lower Case Conversion\n",
    "- Tokenization (Already pre-tokenized is provided by `Google Conceptual Caption`)\n",
    "- Remove stop words\n",
    "- Remove non-alphabets\n",
    "- Keep only nouns\n",
    "- Lemmatization (to store the object name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363,
     "referenced_widgets": [
      "33ebb52bcae948839b911c30f86d1ea6",
      "2dc1e610870d4c3ea65ef96f9def47b2",
      "e8b1735596864545a94d85d2f02fd1e6",
      "a642eca5e34649ce84ce47fd9f11bee6",
      "ad92948248264f4cb98b40f2b6eec143",
      "1b4d3c4593f34f2ab2ec01eabac0a21c",
      "8653e80ce4304b0bbcfd14a5e90952c0",
      "01e45d867ff4434e8bde895e1edc78cf",
      "e2d3d80aa1a24b36a52a2a30bb913dec",
      "738c7ede99654dd59aa46ecf4b7ac804",
      "3cb79e7831a24df38809bd9c27e8a6d3"
     ]
    },
    "id": "yOBU-9eoBD87",
    "outputId": "ea7c4a43-9597-4c06-ea19-9b746e26406b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 19:20:46 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb5f518bfb241b787caa1f479ff9679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-06 19:20:47 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2023-01-06 19:20:47 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "========================\n",
      "\n",
      "2023-01-06 19:20:47 INFO: Use device: cpu\n",
      "2023-01-06 19:20:47 INFO: Loading: tokenize\n",
      "2023-01-06 19:20:47 INFO: Loading: pos\n",
      "2023-01-06 19:20:47 INFO: Loading: lemma\n",
      "2023-01-06 19:20:47 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# loads the text processing pipeline\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma', tokenize_no_ssplit=True, tokenize_pretokenized=True, verbose=True, pos_batch_size=10000)\n",
    "\n",
    "# treebank-specific POS (XPOS) tags to keep, other POS tagged tokens will not be retained\n",
    "keep_pos_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "# Stopwords\n",
    "stpwords = set(stopwords.words('english'))\n",
    "\n",
    "# extract parts of speech\n",
    "def extract_pos(doc):\n",
    "  parsed_text = list()\n",
    "  for sent in doc.sentences:\n",
    "    parsed_sent = list()\n",
    "    for wrd in sent.words:\n",
    "      #extract text and pos\n",
    "      parsed_sent.append((wrd.text, wrd.xpos))\n",
    "    parsed_text.append(parsed_sent)\n",
    "  return parsed_text\n",
    "\n",
    "# extract lemma\n",
    "def extract_lemma(doc):\n",
    "  parsed_text = list()\n",
    "  for sent in doc.sentences:\n",
    "    parsed_sent = list()\n",
    "    for wrd in sent.words:\n",
    "      # extract text and lemma\n",
    "      parsed_sent.append((wrd.text, wrd.lemma))\n",
    "    parsed_text.append(parsed_sent)\n",
    "  return parsed_text\n",
    "\n",
    "def clean_prompt(sentences):\n",
    "  # convert the sentences to lower case\n",
    "  sentences_lc = [sentence.lower() for sentence in sentences]\n",
    "\n",
    "  # stanza accepts only a single string instead of list of strings. So, we have set the tokenize_no_ssplit=True and have to join each sentence with double newline\n",
    "  sentence_string = \"\\n\\n\".join(sentences_lc)\n",
    "\n",
    "  # tokenizes, lemmatizes and pos tags the prompt\n",
    "  processed_prompt = nlp(sentence_string)\n",
    "  \n",
    "  # extracts pos tags from the processed_prompt\n",
    "  pos_tagged_prompt = extract_pos(processed_prompt)\n",
    "\n",
    "  # lemmatized text\n",
    "  lemmatized_prompt = extract_lemma(processed_prompt)\n",
    "\n",
    "  # keep only the noun words, removes stopwords\n",
    "  fin_prompt = [[word for word, pos_tag in sent if ((pos_tag in keep_pos_tags) and (word not in stpwords))] for sent in pos_tagged_prompt]\n",
    "  obj_prompt = [[word_lemma[1] for word_pos, word_lemma in zip(sent_pos, sent_lemma) if ((word_pos[1] in keep_pos_tags) and ((word_lemma[0] not in stpwords) or (word_lemma[1] not in stpwords)))] for sent_pos, sent_lemma in zip(pos_tagged_prompt, lemmatized_prompt)]\n",
    "  return fin_prompt, obj_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCs7sDaJiY6h"
   },
   "source": [
    "An example is shown below for the application of `clean_prompt`. (See how the punctuation stayed intact below on my example as we have set `tokenize_pretokenized=True` as `GCC` provides tokenized captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ez5_quWfXbDM",
    "outputId": "54fcbaf6-b7c2-4846-cb46-01c5399bcc16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['fishes', 'mountains.']], [['fish', 'mountains.']])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_prompt([\"The fishes are playing in the mountains.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2U2RtyiwO2n"
   },
   "source": [
    "But see how it works for captions in `GCC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7hS1SzbYwOb3",
    "outputId": "7720c508-b84b-46c1-8742-8cf5670af031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a very typical bus station\n",
      "sierra looked stunning in this top and this skirt while performing with person at their former university\n",
      "young confused girl standing in front of a wardrobe\n",
      "interior design of modern living room with fireplace in a new house\n",
      "cybernetic scene isolated on white background .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['bus', 'station'],\n",
       "  ['sierra', 'top', 'skirt', 'person', 'university'],\n",
       "  ['girl', 'front', 'wardrobe'],\n",
       "  ['interior', 'design', 'living', 'room', 'fireplace', 'house'],\n",
       "  ['scene', 'background']],\n",
       " [['bus', 'station'],\n",
       "  ['sierra', 'top', 'skirt', 'person', 'university'],\n",
       "  ['girl', 'front', 'wardrobe'],\n",
       "  ['interior', 'design', 'living', 'room', 'fireplace', 'house'],\n",
       "  ['scene', 'background']])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n'.join(prompts_train[:5]))\n",
    "clean_prompt(prompts_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eReFjwGO138w"
   },
   "source": [
    "Below, we start processing each prompt and store the objects detected in the captions from train and validation split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rl4GS3OqREKL"
   },
   "source": [
    "We start with the training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Rp7UjBLEKsxA"
   },
   "outputs": [],
   "source": [
    "SAVE_AFTER = 10000 # After parsing how many sentences should I save the outputs (should be less than len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "o3layVVd62BE"
   },
   "outputs": [],
   "source": [
    "# import shutil # Removes directory if already present! CAREFUL!!!!!!!!!!!!!!!!!!\n",
    "# if os.path.exists(os.path.join(PATH, 'Caption-Processing1')):\n",
    "#   shutil.rmtree(os.path.join(PATH, 'Caption-Processing1'))\n",
    "# os.mkdir(os.path.join(PATH, 'Caption-Processing1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IVeokhggMHqw"
   },
   "outputs": [],
   "source": [
    "SAVE_SPLITS = list(range(0, len(prompts_train), SAVE_AFTER)) # Figure out the sentences in each split\n",
    "if SAVE_SPLITS[-1] < (len(prompts_train) - 1):\n",
    "  SAVE_SPLITS.append(len(prompts_train)) # Adding the last split boundary to be the final index of the prompts to make sure the boundaries work when subsetting later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_R3pmpTnEtS6",
    "outputId": "0f871599-3c0c-43a8-c150-5193e84e71bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "Captions to be processed: 3318333\n",
      "Number of splits to be processed: 332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/332 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subset No. 1\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1490566.12it/s]\n",
      "  0%|                                         | 1/332 [00:43<3:57:30, 43.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 10000\n",
      "Number of objects detected so far: 4175\n",
      "Saving...Saved.\n",
      "\n",
      "Subset No. 2\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1450112.02it/s]\n",
      "  1%|▏                                        | 2/332 [01:28<4:03:27, 44.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 20000\n",
      "Number of objects detected so far: 5349\n",
      "Saving...Saved.\n",
      "\n",
      "Subset No. 3\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1343165.85it/s]\n",
      "  1%|▎                                        | 3/332 [02:12<4:01:52, 44.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 30000\n",
      "Number of objects detected so far: 6068\n",
      "Saving...Saved.\n",
      "\n",
      "Subset No. 4\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1472357.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 40000\n",
      "Number of objects detected so far: 6561\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▍                                        | 4/332 [02:55<3:58:55, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 5\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1384670.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 50000\n",
      "Number of objects detected so far: 6945\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▌                                        | 5/332 [03:40<4:00:59, 44.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 6\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1404703.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 60000\n",
      "Number of objects detected so far: 7294\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▋                                        | 6/332 [04:26<4:03:12, 44.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 7\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1508308.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 70000\n",
      "Number of objects detected so far: 7564\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▊                                        | 7/332 [05:12<4:04:30, 45.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 8\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1363114.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 80000\n",
      "Number of objects detected so far: 7820\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▉                                        | 8/332 [05:56<4:03:00, 45.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 9\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1342993.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 90000\n",
      "Number of objects detected so far: 8023\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|█                                        | 9/332 [06:41<4:01:43, 44.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 10\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1475984.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 100000\n",
      "Number of objects detected so far: 8203\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|█▏                                      | 10/332 [07:25<3:59:46, 44.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 11\n",
      "Processing captions...\n",
      "Updating captions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "10000it [00:00, 1346097.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "***INFO***\n",
      "Captions Processed: 110000\n",
      "Number of objects detected so far: 8359\n",
      "Saving..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|█▎                                      | 11/332 [08:11<4:00:47, 45.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n",
      "\n",
      "Subset No. 12\n",
      "Processing captions...\n"
     ]
    }
   ],
   "source": [
    "total_objects = set() # Stores the total number of distinct objects detected\n",
    "num_objects_detected = list() # Stores number of objects detected after processing some number of prompts iteratively\n",
    "caption_data_train_file = {'annotations':[]} # For storing results\n",
    "\n",
    "print('Starting...')\n",
    "print('Captions to be processed:', len(prompts_train))\n",
    "print('Number of splits to be processed:', len(SAVE_SPLITS)-1)\n",
    "\n",
    "for i in tqdm(range(len(SAVE_SPLITS)-1)):\n",
    "  print()\n",
    "  print(f'Subset No. {i+1}')\n",
    "  curr_split_data = prompts_train[SAVE_SPLITS[i]:SAVE_SPLITS[i+1]] # Current split of data\n",
    "  print('Processing captions...')\n",
    "  processed_train = clean_prompt(curr_split_data) # start processing the train captions subset\n",
    "  print(f'Updating captions...')\n",
    "  # Processing each prompt and updating annotation file for train set\n",
    "  update_data = [{'caption': prompt} for prompt in curr_split_data]\n",
    "  cleaned_prompts, object_prompts = processed_train\n",
    "  for idx, prompt in tqdm(enumerate(zip(cleaned_prompts, object_prompts))):\n",
    "    cleaned, objects = prompt # Process prompt\n",
    "    # update files and object list\n",
    "    update_data[idx]['cleaned'] = cleaned\n",
    "    update_data[idx]['objects'] = objects\n",
    "    total_objects.update(set(objects))\n",
    "\n",
    "  print()\n",
    "  print()\n",
    "  print('***INFO***')\n",
    "  print('Captions Processed:', SAVE_SPLITS[i+1])\n",
    "  print('Number of objects detected so far:', len(total_objects))\n",
    "  num_objects_detected.append(len(total_objects))\n",
    "\n",
    "  caption_data_train_file['annotations'].extend(update_data) # updating the data for saving\n",
    "  print('Saving...', end='')\n",
    "\n",
    "  # Save the processed captions data so far\n",
    "  with open(os.path.join(PATH, 'Data-Captions/GCC/train-captions-processed.json'), 'w') as outfile: # Save Results in json\n",
    "    outfile.write(json.dumps(caption_data_train_file, indent=4))\n",
    "\n",
    "  # Save the objects detected info so far\n",
    "  with open(os.path.join(PATH, 'Data-Captions/GCC/train-objects.json'), 'w') as outfile: # Saving Total objects in json\n",
    "    outfile.write(json.dumps({'objects': list(total_objects), 'num_objects': num_objects_detected}, indent=4))\n",
    "\n",
    "  print('Saved.')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WFO0_PAEOeY",
    "outputId": "ac5b3664-b18e-4477-8841-54e5ae0960b4"
   },
   "outputs": [],
   "source": [
    "print(total_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMvs_tHrQ_4y"
   },
   "source": [
    "For the validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugGRwWapRCys"
   },
   "outputs": [],
   "source": [
    "SAVE_SPLITS = list(range(0, len(prompts_val), SAVE_AFTER)) # Figure out the sentences in each split\n",
    "if SAVE_SPLITS[-1] < (len(prompts_val) - 1):\n",
    "  SAVE_SPLITS.append(len(prompts_val)) # Adding the last split boundary to be the final index of the prompts to make sure the boundaries work when subsetting later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IhTuA9i1RNg1",
    "outputId": "c52a5ed5-c82f-447e-e727-d0ad015e27c2"
   },
   "outputs": [],
   "source": [
    "total_objects = set() # Stores the total number of distinct objects detected\n",
    "num_objects_detected = list() # Stores number of objects detected after processing some number of prompts iteratively\n",
    "caption_data_val_file = {'annotations':[]} # For storing results\n",
    "\n",
    "print('Starting...')\n",
    "print('Captions to be processed:', len(prompts_val))\n",
    "print('Number of splits to be processed:', len(SAVE_SPLITS)-1)\n",
    "\n",
    "for i in tqdm(range(len(SAVE_SPLITS)-1)):\n",
    "\n",
    "  print(f'Subset No. {i+1}')\n",
    "  curr_split_data = prompts_val[SAVE_SPLITS[i]:SAVE_SPLITS[i+1]] # Current split of data\n",
    "  print('Processing captions...')\n",
    "  processed_val = clean_prompt(curr_split_data) # start processing the train captions subset\n",
    "  print(f'Updating captions...')\n",
    "  # Processing each prompt and updating annotation file for train set\n",
    "  update_data = [{'caption': prompt} for prompt in curr_split_data]\n",
    "  cleaned_prompts, object_prompts = processed_val\n",
    "  for idx, prompt in tqdm(enumerate(zip(cleaned_prompts, object_prompts))):\n",
    "    cleaned, objects = prompt # Process prompt\n",
    "    # update files and object list\n",
    "    update_data[idx]['cleaned'] = cleaned\n",
    "    update_data[idx]['objects'] = objects\n",
    "    total_objects.update(set(objects))\n",
    "    \n",
    "  print()\n",
    "  print()\n",
    "  print('***INFO***')\n",
    "  print('Captions Processed:', SAVE_SPLITS[i+1])\n",
    "  print('Number of objects detected so far:', len(total_objects))\n",
    "  num_objects_detected.append(len(total_objects))\n",
    "  print()\n",
    "\n",
    "  caption_data_val_file['annotations'].extend(update_data) # updating the data for saving\n",
    "  print('Saving...')\n",
    "\n",
    "  # Save the processed captions data so far\n",
    "  with open(os.path.join(PATH, 'Data-Captions/GCC/val-captions-processed.json'), 'w') as outfile: # Save Results in json\n",
    "    outfile.write(json.dumps(caption_data_val_file, indent=4))\n",
    "\n",
    "  # Save the objects detected info so far\n",
    "  with open(os.path.join(PATH, 'Data-Captions/GCC/val-objects.json'), 'w') as outfile: # Saving Total objects in json\n",
    "    outfile.write(json.dumps({'objects': list(total_objects), 'num_objects': num_objects_detected}, indent=4))\n",
    "\n",
    "  print('Saved and Finished Processing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlrSnDEoC2FM",
    "outputId": "1d119f79-7595-47b0-aa3d-dfadd70ef821"
   },
   "outputs": [],
   "source": [
    "print(total_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tl18GNA8V3Wy"
   },
   "source": [
    "Now, we look at how each additional prompt helped in increasing the number of unique objects in the `total_objects`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMe2cz6WC3O0"
   },
   "outputs": [],
   "source": [
    "# Load the objects set for train set\n",
    "with open(os.path.join(PATH, 'Data-Captions/GCC/train-objects.json')) as json_file:\n",
    "  train_objects_file = json.load(json_file)\n",
    "\n",
    "# Load the objects set for val set\n",
    "with open(os.path.join(PATH, 'Data-Captions/GCC/val-objects.json')) as json_file:\n",
    "  val_objects_file = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngElA01uWdpG"
   },
   "source": [
    "Plots are more visually appealing and revealing let's plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "9oMj4BMvWZ-2",
    "outputId": "d0838f9e-303c-492c-8622-8123672c902b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(train_objects_file['num_objects'])\n",
    "plt.xlabel(f'Number of Prompts processed (1 unit = {SAVE_AFTER} prompts)')\n",
    "plt.ylabel('Number of unique objects extracted')\n",
    "plt.title('Objects Extracted from Google Conceptual Captions (train split)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "GMx2r-2oWvfk",
    "outputId": "77033913-13e6-4646-ec39-fc226dd756d7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "plt.plot(val_objects_file['num_objects'])\n",
    "plt.xlabel(f'Number of Prompts processed (1 unit = {SAVE_AFTER} prompts)')\n",
    "plt.ylabel('Number of unique objects extracted')\n",
    "plt.title('Objects Extracted from Google Conceptual Captions (validation split)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1B2hJjOYE4J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01e45d867ff4434e8bde895e1edc78cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0540e337651b4a158d5dffabb494d745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "13293d3dbf7d4fb580c772e0e0dfcc9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14391e8237d44f2ba6e1890828233088": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b4d3c4593f34f2ab2ec01eabac0a21c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1fbdc06fb1544d53a05533382b9c0062": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13293d3dbf7d4fb580c772e0e0dfcc9e",
      "max": 28918,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0540e337651b4a158d5dffabb494d745",
      "value": 28918
     }
    },
    "20127b2249424758aaac276817af28a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_325f39c1cb444e9b85a2360323d204ce",
      "placeholder": "​",
      "style": "IPY_MODEL_d3155ecf834340609b9dc25df5cec3a2",
      "value": " 561M/561M [00:05&lt;00:00, 98.2MB/s]"
     }
    },
    "2da511597a914db7b4ddf749852b331d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2dc1e610870d4c3ea65ef96f9def47b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b4d3c4593f34f2ab2ec01eabac0a21c",
      "placeholder": "​",
      "style": "IPY_MODEL_8653e80ce4304b0bbcfd14a5e90952c0",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
     }
    },
    "325f39c1cb444e9b85a2360323d204ce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33ebb52bcae948839b911c30f86d1ea6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2dc1e610870d4c3ea65ef96f9def47b2",
       "IPY_MODEL_e8b1735596864545a94d85d2f02fd1e6",
       "IPY_MODEL_a642eca5e34649ce84ce47fd9f11bee6"
      ],
      "layout": "IPY_MODEL_ad92948248264f4cb98b40f2b6eec143"
     }
    },
    "365f9fc1f1f44502b22abe715e797a10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9710fd246f1943258ba37cc8d6454b62",
      "placeholder": "​",
      "style": "IPY_MODEL_5ac46403bd4044318527c0adfed0f672",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json: "
     }
    },
    "3cb79e7831a24df38809bd9c27e8a6d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ac46403bd4044318527c0adfed0f672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67fcbabbc7e94682a8d032fe4ed5144d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ecc24e7ae09b432599b2ee56a4a57e09",
      "placeholder": "​",
      "style": "IPY_MODEL_72f1b6b4703740fca72516e15c0214fd",
      "value": " 193k/? [00:00&lt;00:00, 4.72MB/s]"
     }
    },
    "6b61994192e74430957f414859c3c28f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f0f42079f8d48f6a82daab7cc927076": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fb4da8ef7a04451487731260764d7468",
       "IPY_MODEL_c1ea0ca2be8f4cd39a5168fdced8264a",
       "IPY_MODEL_20127b2249424758aaac276817af28a5"
      ],
      "layout": "IPY_MODEL_14391e8237d44f2ba6e1890828233088"
     }
    },
    "71845a3840d54187b7120b16c8406194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72f1b6b4703740fca72516e15c0214fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "738c7ede99654dd59aa46ecf4b7ac804": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8653e80ce4304b0bbcfd14a5e90952c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9710fd246f1943258ba37cc8d6454b62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a642eca5e34649ce84ce47fd9f11bee6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738c7ede99654dd59aa46ecf4b7ac804",
      "placeholder": "​",
      "style": "IPY_MODEL_3cb79e7831a24df38809bd9c27e8a6d3",
      "value": " 193k/? [00:00&lt;00:00, 4.75MB/s]"
     }
    },
    "ad92948248264f4cb98b40f2b6eec143": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1ea0ca2be8f4cd39a5168fdced8264a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71845a3840d54187b7120b16c8406194",
      "max": 561333907,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4251c4227fc4efa8d6400bbd4695171",
      "value": 561333907
     }
    },
    "d3155ecf834340609b9dc25df5cec3a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d4251c4227fc4efa8d6400bbd4695171": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4c72b61447b4b78b1e82a2ca93a365c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6b06ecb56f423682c0b81450369c68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_365f9fc1f1f44502b22abe715e797a10",
       "IPY_MODEL_1fbdc06fb1544d53a05533382b9c0062",
       "IPY_MODEL_67fcbabbc7e94682a8d032fe4ed5144d"
      ],
      "layout": "IPY_MODEL_2da511597a914db7b4ddf749852b331d"
     }
    },
    "e2d3d80aa1a24b36a52a2a30bb913dec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e8b1735596864545a94d85d2f02fd1e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01e45d867ff4434e8bde895e1edc78cf",
      "max": 28918,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2d3d80aa1a24b36a52a2a30bb913dec",
      "value": 28918
     }
    },
    "ecc24e7ae09b432599b2ee56a4a57e09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb4da8ef7a04451487731260764d7468": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4c72b61447b4b78b1e82a2ca93a365c",
      "placeholder": "​",
      "style": "IPY_MODEL_6b61994192e74430957f414859c3c28f",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.4.1/models/default.zip: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
